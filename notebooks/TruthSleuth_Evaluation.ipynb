{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cecileloge/cs224v-truthsleuth-trendbender/blob/main/notebooks/TruthSleuth_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Truth Sleuth AI: Fact-Checking Agent for YouTube Videos | EVALUATION**\n",
        "**Cecile Loge ep. Baccari** | ceciloge@stanford.edu | cecileloge@google.com \\\\\n",
        "**Mohammad Rehan Ghori** | rghori@stanford.edu | rehang@google.com\n",
        "\n",
        "---\n",
        "\n",
        "**Motivation:** Misinformation is one of the most pressing threats of our time, and YouTube videos serve as a major platform through which it can spread [1]. Providing fact-checked information to address misleading content has been shown to be more effective than simply removing it [2].\n",
        "\n",
        "**Project:** Can we build an application that takes a YouTube video as input and not only generates a list of the main claims made in the video but also fact-checks them?\n",
        "\n",
        "---\n",
        "\n",
        "* [1] An open letter to YouTube’s CEO from the world’s fact-checkers (on poynter.org), 2022. \\\\\n",
        "* [2] Ecker, Ullrich KH, et al. \"The effectiveness of short‐format refutational fact‐checks.\" British journal of psychology 111.1 (2020): 36-54."
      ],
      "metadata": {
        "id": "W_jcGO58h939"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Setting Up Everything**\n",
        "Choosing the YouTube video url, and installing/importing libraries.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "iOdGDcTj2dg8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPwx_gkvhCLJ",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5445b15e-f508-4055-c644-39ddc3fcb70f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done!\n"
          ]
        }
      ],
      "source": [
        "# Install & Import Libraries\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "# Youtube Extractors\n",
        "!pip install youtube-transcript-api\n",
        "!pip install pytube\n",
        "!pip install -U yt-dlp\n",
        "!apt install ffmpeg\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from pytube import extract\n",
        "\n",
        "# Assembly AI\n",
        "!pip install assemblyai\n",
        "import assemblyai as aai\n",
        "\n",
        "# Data & Tools\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "current_dir = os.getcwd()\n",
        "from datetime import datetime, date\n",
        "import time\n",
        "\n",
        "# Google API\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "# Markdown for the final output\n",
        "from IPython.display import display, Markdown, Latex\n",
        "import textwrap\n",
        "\n",
        "# Gemini API\n",
        "!pip install -q -U google-generativeai\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# LangChain Prompting\n",
        "!pip install langchain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "# For Web Scraping\n",
        "!pip install requests\n",
        "!pip install beautifulsoup4\n",
        "!pip install wikipedia\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import wikipedia\n",
        "import googlesearch as g\n",
        "\n",
        "clear_output()\n",
        "print(\"done!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YouTube API Key (Google for Developers Platform)\n",
        "DEVELOPER_KEY=userdata.get('DEVELOPER_KEY')\n",
        "\n",
        "# Google Developer API Key for GenAI\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY2')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "GEM_SAFETY_SETTINGS = [\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "      \"threshold\": \"BLOCK_NONE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      \"threshold\": \"BLOCK_NONE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_NONE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      \"threshold\": \"BLOCK_NONE\"\n",
        "    }\n",
        "    ]\n",
        "\n",
        "# Assembly AI API Key\n",
        "AAI_API_KEY = userdata.get('AAI_API_KEY')\n",
        "aai.settings.api_key = AAI_API_KEY"
      ],
      "metadata": {
        "id": "-YQmckZyELCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt Templates\n",
        "!mkdir prompts\n",
        "!curl -L -o prompts/reformat.prompt \"https://drive.google.com/uc?export=download&id=1aykUMXxUR1gWOil5X83aF7aem1s5rjIT\"\n",
        "!curl -L -o prompts/claims.prompt \"https://drive.google.com/uc?export=download&id=1AlKLI-IP05jMps4Ol7BN2RPcmAMH2H-J\"\n",
        "!curl -L -o prompts/factcheck.prompt \"https://drive.google.com/uc?export=download&id=1cevbk44t7ZWJr3rwpu-b1ncqHYdq-p8x\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mvGIxf1Jt6S",
        "outputId": "7a4d9c25-9903-4120-99e4-1e11b6838eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100   224  100   224    0     0    102      0  0:00:02  0:00:02 --:--:--   116\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  8614  100  8614    0     0   3247      0  0:00:02  0:00:02 --:--:--  6734\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  4630  100  4630    0     0   1808      0  0:00:02  0:00:02 --:--:--  2040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **[EVALUATION] STEP 3 | Fact-checking the claims by cross-checking reliable sources**\n",
        "\n",
        "Cross-reference claims with reliable sources, and classify claims into true, unsure and false (ideally with links / sources).\n",
        "\n",
        "\n",
        "This step leverages the Google FactCheck Claim Search API, the Wikipedia API and Google Search.\n",
        "\n",
        "The LLM is called several times throughout this step via robust prompt engineering to interpret, cross-reference, and ultimately classify the claims.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "D_LDf7hiDUAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Our reliable sources for Fact-Checking\n",
        "# 1 - Google Fact-Check API\n",
        "GOOGLE_FACT_CHECK_API_KEY = userdata.get('GFC_API_KEY')\n",
        "GOOGLE_FACT_CHECK_URL = 'https://factchecktools.googleapis.com/v1alpha1/claims:search'\n",
        "\n",
        "# 2 - Wikipedia\n",
        "wikipedia.set_lang('en')\n",
        "\n",
        "# 3 - Google Search\n",
        "GOOGLE_USER_AGENT = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36\""
      ],
      "metadata": {
        "id": "gufqI6AqsYK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_googlefacts(claim):\n",
        "  \"\"\"\n",
        "  Function to call the Google Fact Check API\n",
        "  Returns the claim reviews in the Claim Review structured format\n",
        "  https://developers.google.com/search/docs/appearance/structured-data/factcheck\n",
        "  \"\"\"\n",
        "\n",
        "  params = {\n",
        "      'query': claim,\n",
        "      'key': GOOGLE_FACT_CHECK_API_KEY\n",
        "  }\n",
        "  response = requests.get(GOOGLE_FACT_CHECK_URL, params=params)\n",
        "  if response.status_code == 200:\n",
        "      data = response.json()\n",
        "      return data.get('claims', [])\n",
        "  else:\n",
        "      return None\n",
        "\n",
        "def check_googlefacts(claim):\n",
        "  \"\"\"\n",
        "  Function to process the Google Fact Check claim reviews\n",
        "  Returns a string = concatenation of relevant results\n",
        "  \"\"\"\n",
        "  results = call_googlefacts(claim)\n",
        "  summary = ''\n",
        "  if results:\n",
        "      for i, r in enumerate(results):\n",
        "          source = r.get('claimReview', [{}])[0].get('publisher').get('name')\n",
        "          url = r.get('claimReview', [{}])[0].get('url')\n",
        "          claimant = r.get('claimant')\n",
        "          date = r.get('claimDate')\n",
        "          text = r.get('text')\n",
        "          truthfulness = r.get('claimReview', [{}])[0].get('textualRating')\n",
        "          summary += f\"Source #{i+1}: {source} at {url}.\\n     Claimant: {claimant}\\n     Description: {text}\\n     Truthfulness: {truthfulness}\\n\\n\"\n",
        "\n",
        "  return summary\n",
        "\n",
        "def check_googlesearch(claim, limit=2):\n",
        "  \"\"\"\n",
        "  Function to call the Google Search API\n",
        "  Calls Gemini to process the results and generate a summary\n",
        "  Returns a string = concatenation of relevant results\n",
        "  \"\"\"\n",
        "  urls = list(g.search(claim, stop=limit, lang='en'))\n",
        "  headers = {\"user-agent\": GOOGLE_USER_AGENT}\n",
        "  summary = ''\n",
        "  for url in urls:\n",
        "    session = requests.Session()\n",
        "    website = session.get(url, headers=headers)\n",
        "    web_soup = BeautifulSoup(website.text, 'html.parser')\n",
        "    summary_promt = \"I need you to give me the key information contained in a specific webpage article. I will provide you with html code. '\\\n",
        "    Do not describe the webpage or the article. Focus on extracting the key claims, and summarizing the information the page is giving in a precise, comprehensive yet concise way. '\\\n",
        "    Your answer should ideally help answer the question: \" + claim + \".\\n'\\\n",
        "    HTLM Code: <<< \" + str(web_soup) + \" >>>\"\n",
        "    retry_count = 0\n",
        "    k = random.randint(1, 3)\n",
        "    time.sleep(k)\n",
        "    while retry_count < 3:\n",
        "      try:\n",
        "        response = model.generate_content(summary_promt, safety_settings=GEM_SAFETY_SETTINGS)\n",
        "        summary += f\"Source: {url}.\\nDescription: {response.text}\\n\"\n",
        "        retry_count = 3\n",
        "      except Exception as e:\n",
        "        k = random.randint(2, 7)\n",
        "        time.sleep(k)\n",
        "        retry_count += 1\n",
        "    session.close()\n",
        "  return summary\n",
        "\n",
        "def check_wikipedia(claim):\n",
        "  \"\"\"\n",
        "  Function to call the Wikipedia API and process the results\n",
        "  Returns a string = concatenation/summary of relevant Wikipedia articles\n",
        "  \"\"\"\n",
        "  summary = ''\n",
        "  search_results = wikipedia.search(claim)\n",
        "  for r in search_results[:4]:\n",
        "    try:\n",
        "      call = wikipedia.page(r)\n",
        "      summary += f\"From the \\\"{r}\\\" Wikipedia page ({call.url}): \"+ call.content +\"\\n\\n\"\n",
        "    except wikipedia.exceptions.DisambiguationError:\n",
        "      summary += ''\n",
        "    except wikipedia.exceptions.PageError:\n",
        "      summary += ''\n",
        "    except wikipedia.exceptions.WikipediaException:\n",
        "      summary += ''\n",
        "    except Exception:\n",
        "      summary += ''\n",
        "  return summary"
      ],
      "metadata": {
        "id": "sANlwtp9XIT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_claim_summary(claim, questions):\n",
        "  \"\"\"\n",
        "  Function to get the final say on a specific claim.\n",
        "  Calls Gemini with the factcheck.prompt prompt.\n",
        "  Returns json object with fields: `claim`, `verdict`, `reason`, `sources`.\n",
        "  \"\"\"\n",
        "  summary_gfc = ''\n",
        "  summary_search = ''\n",
        "  for q in questions:\n",
        "    if q == '':\n",
        "      continue\n",
        "    gfc = check_googlefacts(q)\n",
        "    if gfc:\n",
        "      summary_gfc += gfc + \"\\n\"\n",
        "  for q in questions:\n",
        "    if q == '':\n",
        "      continue\n",
        "    search = check_googlesearch(q)\n",
        "    summary_search += search + \"\\n\"\n",
        "  summary_wiki = check_wikipedia(claim)\n",
        "\n",
        "  with open(\"prompts/factcheck.prompt\", \"r\") as f:\n",
        "        text = f.read()\n",
        "  prompt_template = PromptTemplate.from_template(template=text, template_format=\"jinja2\")\n",
        "  fact_check_prompt: str = prompt_template.format(\n",
        "      claim=claim,\n",
        "      report_GFC=summary_gfc + \"\\n\" + summary_search,\n",
        "      report_wiki=summary_wiki,\n",
        "      )\n",
        "\n",
        "  retry_count = 0\n",
        "  k = random.randint(1, 3)\n",
        "  time.sleep(k)\n",
        "  while retry_count < 3:\n",
        "      try:\n",
        "         response = model.generate_content(fact_check_prompt, safety_settings=GEM_SAFETY_SETTINGS)\n",
        "         return response.text\n",
        "      except Exception as e:\n",
        "         #print(f\"Error: {e}\")\n",
        "         k = random.randint(4, 8)\n",
        "         time.sleep(k)\n",
        "      retry_count += 1\n",
        "  return None"
      ],
      "metadata": {
        "id": "BeYIhFT0hW3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **FeVER Dataset**\n",
        "\n",
        "Evaluating the Fact-Checking abilities with the FeVER Dataset.\n",
        "\n",
        "\n",
        "Thorne, James, et al. \"FEVER: a large-scale dataset for fact extraction and VERification.\" arXiv preprint arXiv:1803.05355 (2018).\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "9m5eeMQpFShD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('paper_test.jsonl') as f:\n",
        "    data = [json.loads(line) for line in f]\n",
        "\n",
        "for element in data:\n",
        "  del element[\"id\"]\n",
        "  del element[\"verifiable\"]\n",
        "  del element[\"evidence\"]\n",
        "\n",
        "fever = [x for x in data if x['label'] != 'NOT ENOUGH INFO']\n",
        "fever = fever[50:100]"
      ],
      "metadata": {
        "id": "O3QaZIC7H_lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, element in enumerate(fever):\n",
        "  print(f\"element {i+1}\")\n",
        "  print(element)\n",
        "  p = f\"Output a list of 2 or 3 simple factual questions rephrasing the following claim: << {element['claim']} >>. \\\n",
        "  Questions should be factual and simple such that each single question contains only one single fact and can be answered through public records. \\\n",
        "  Each question should be able to be understood and provide enough context on its own. Write nothing more than the questions.\"\n",
        "  response = model.generate_content(p, safety_settings=GEM_SAFETY_SETTINGS)\n",
        "  k = random.randint(1, 5)\n",
        "  time.sleep(k)\n",
        "  element[\"questions\"] = response.text.split(\"\\n\")\n",
        "  clear_output()\n"
      ],
      "metadata": {
        "id": "tZ9czlxoMd-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, element in enumerate(fever):\n",
        "  print(f\"element {i+1}\")\n",
        "  print(element)"
      ],
      "metadata": {
        "id": "Vghzro2CE7c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, element in enumerate(fever):\n",
        "  print(f\"element {i+1}\")\n",
        "  print(element)\n",
        "  text = get_claim_summary(element[\"claim\"], element[\"questions\"])\n",
        "  if text == None:\n",
        "    element[\"verdict\"] = \"unsure\"\n",
        "    continue\n",
        "  try:\n",
        "    verdict = json.loads(text)\n",
        "  except json.JSONDecodeError:\n",
        "    verdict = json.loads(text[8:-4])\n",
        "\n",
        "  element[\"verdict\"] = verdict.get('verdict')\n",
        "  clear_output()"
      ],
      "metadata": {
        "id": "kytkcagWI09i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capped = {\"true\": \"SUPPORTS\", \"partly true\": \"SUPPORTS\", \"partly false\": \"REFUTES\", \"false\": \"REFUTES\", \"unsure\": \"NOT ENOUGH INFO\"}\n",
        "TP = 0 #True Positives from all but FALSE\n",
        "TN = 0 #True Negatives from FALSE\n",
        "FP = 0 #False Positives from all but FALSE\n",
        "FN = 0 #False Negatives from FALSE\n",
        "NE = 0 #Not enough info\n",
        "\n",
        "for element in fever:\n",
        "  element[\"final\"] = capped[element[\"verdict\"]]\n",
        "  if element[\"label\"] == element[\"final\"]:\n",
        "    if element[\"label\"] == \"REFUTES\":\n",
        "      TN += 1\n",
        "    else:\n",
        "      TP +=1\n",
        "  elif element[\"label\"] == \"REFUTES\" and element[\"final\"] == \"SUPPORTS\":\n",
        "    FP += 1\n",
        "  elif element[\"label\"] == \"SUPPORTS\" and element[\"final\"] == \"REFUTES\":\n",
        "    FN += 1\n",
        "  else:\n",
        "    NE +=1\n",
        "\n",
        "print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}, NE: {NE}\")\n"
      ],
      "metadata": {
        "id": "DdglGLjnVNBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Precision = TP / (TP + FP)\n",
        "Recall = TP / (TP + FN)\n",
        "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "print(f\"Precision: {Precision}, Recall: {Recall}, Accuracy: {Accuracy}, F1: {F1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x8G4gdRXleS",
        "outputId": "854662ed-21f9-447c-a6b9-b5ef2f19ec78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9523809523809523, Recall: 0.9523809523809523, Accuracy: 0.9574468085106383, F1: 0.9523809523809523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **AVeriTeC Dataset**\n",
        "\n",
        "Evaluating the Fact-Checking abilities with the AVeriTeC Dataset.\n",
        "\n",
        "\n",
        "AVERITEC: A Dataset for Real-world Claim Verification with Evidence from the Web\n",
        "Michael Schlichtkrull, Zhijiang Guo, Andreas Vlachos\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "M88sAROSW1Et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('data_dev.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "for element in data:\n",
        "  del element[\"required_reannotation\"]\n",
        "  del element[\"justification\"]\n",
        "  del element[\"claim_date\"]\n",
        "  del element[\"speaker\"]\n",
        "  del element[\"original_claim_url\"]\n",
        "  del element[\"fact_checking_article\"]\n",
        "  del element[\"reporting_source\"]\n",
        "  del element[\"location_ISO_code\"]\n",
        "  del element[\"claim_types\"]\n",
        "  del element[\"fact_checking_strategies\"]\n",
        "  del element[\"questions\"]\n",
        "  if \"cached_original_claim_url\" in element:\n",
        "    del element[\"cached_original_claim_url\"]\n",
        "\n",
        "averitec = [x for x in data if (x['label'] == 'Supported' or x['label'] == 'Refuted')]\n",
        "averitec = averitec[50:100]"
      ],
      "metadata": {
        "id": "9JkqjDbrXIv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, element in enumerate(averitec[27:32]):\n",
        "  print(f\"element {i+1}\")\n",
        "  print(element)\n",
        "  p = f\"Output a list of 1 or 2 simple factual questions rephrasing the following claim: << {element['claim']} >>. \\\n",
        "  Questions should be factual and simple such that each single question contains only one single fact and can be answered through public records. \\\n",
        "  Each question should be able to be understood and provide enough context on its own. Write nothing more than the questions.\"\n",
        "  response = model.generate_content(p, safety_settings=GEM_SAFETY_SETTINGS)\n",
        "  k = random.randint(1, 5)\n",
        "  time.sleep(k)\n",
        "  q_list = response.text.split(\"\\n\")\n",
        "  element[\"questions\"] = [x for x in q_list if x != '']\n",
        "  clear_output()"
      ],
      "metadata": {
        "id": "KIfzupsPZxdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, element in enumerate(averitec[27:32]):\n",
        "  print(f\"element {i+1}\")\n",
        "  print(element)\n",
        "  text = get_claim_summary(element[\"claim\"], element[\"questions\"])\n",
        "  if text == None:\n",
        "    element[\"verdict\"] = \"unsure\"\n",
        "    continue\n",
        "  try:\n",
        "    verdict = json.loads(text)\n",
        "  except json.JSONDecodeError:\n",
        "    verdict = json.loads(text[8:-4])\n",
        "\n",
        "  element[\"verdict\"] = verdict.get('verdict')\n",
        "  clear_output()"
      ],
      "metadata": {
        "id": "3akj7mJxYrk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capped = {\"true\": 'Supported', \"partly true\": 'Supported', \"partly false\": 'Refuted', \"false\": 'Refuted', \"unsure\": \"NOT ENOUGH INFO\"}\n",
        "TP = 0 #True Positives from all but FALSE\n",
        "TN = 0 #True Negatives from FALSE\n",
        "FP = 0 #False Positives from all but FALSE\n",
        "FN = 0 #False Negatives from FALSE\n",
        "NEP = 0 #Not enough info for SUPPORTS\n",
        "NEN = 0 #Not enough info for REFUTES\n",
        "\n",
        "for element in averitec[27:32]:\n",
        "  if \"verdict\" in element:\n",
        "    element[\"final\"] = capped[element[\"verdict\"]]\n",
        "    if element[\"label\"] == element[\"final\"]:\n",
        "      if element[\"label\"] == 'Refuted':\n",
        "        TN += 1\n",
        "      else:\n",
        "        TP +=1\n",
        "    elif element[\"label\"] == 'Refuted' and element[\"final\"] == 'Supported':\n",
        "      FP += 1\n",
        "    elif element[\"label\"] == 'Supported' and element[\"final\"] == 'Refuted':\n",
        "      FN += 1\n",
        "    elif element[\"label\"] == 'Refuted' and element[\"final\"] == \"NOT ENOUGH INFO\":\n",
        "      NEN += 1\n",
        "    elif element[\"label\"] == 'Supported' and element[\"final\"] == \"NOT ENOUGH INFO\":\n",
        "      NEP += 1\n",
        "\n",
        "print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}, NEP: {NEP}, NEN: {NEN}\")"
      ],
      "metadata": {
        "id": "tRZX0mQ3cGxc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}